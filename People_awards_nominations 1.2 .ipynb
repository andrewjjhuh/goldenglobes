{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "People nominees v1.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_F0N2JS3Vbo",
        "outputId": "08b29168-f1d7-4369-c725-a37209151969"
      },
      "source": [
        "pip install git+https://github.com/alberanid/imdbpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/alberanid/imdbpy\n",
            "  Cloning https://github.com/alberanid/imdbpy to /tmp/pip-req-build-0gsavfv6\n",
            "  Running command git clone -q https://github.com/alberanid/imdbpy /tmp/pip-req-build-0gsavfv6\n",
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.7/dist-packages (from IMDbPY==2021.10.24) (1.4.25)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from IMDbPY==2021.10.24) (4.2.6)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy->IMDbPY==2021.10.24) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy->IMDbPY==2021.10.24) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy->IMDbPY==2021.10.24) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy->IMDbPY==2021.10.24) (3.6.0)\n",
            "Building wheels for collected packages: IMDbPY\n",
            "  Building wheel for IMDbPY (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for IMDbPY: filename=IMDbPY-2021.10.24-py3-none-any.whl size=300551 sha256=dc1d70c6ba2992eade60d1ed35ad48ec2bafb2c3554ff72fae25f8c554d8b892\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-f41n9qen/wheels/d1/75/06/4d048b85021fb5f979ece79f70f27550ed04b76f9603dcb0d9\n",
            "Successfully built IMDbPY\n",
            "Installing collected packages: IMDbPY\n",
            "Successfully installed IMDbPY-2021.10.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIFQutooc287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95fe5195-9008-4edf-f863-c5615bb3b4c4"
      },
      "source": [
        "import json\n",
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "import difflib\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('stopwords')\n",
        "from imdb import IMDb\n",
        "import math\n",
        "from collections import Counter\n",
        "WORD = re.compile(r'\\w+')\n",
        "ia = IMDb()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqC2izeAZjZo"
      },
      "source": [
        "mystop_words = stopwords.words('english')\n",
        "mystop_words.extend(['performance','made','-','congrats','congratulations','got','knows','well','well-','hell','yeah','go'])\n",
        "#print(mystop_words)\n",
        "PEOPLE_AWARDS = ['best director - motion picture','best performance by an actress in a television series - comedy or musical','best performance by an actor in a supporting role in a motion picture','best performance by an actress in a supporting role in a series, mini-series or motion picture made for television','best performance by an actress in a motion picture - comedy or musical','best performance by an actress in a television series - drama','best performance by an actress in a motion picture - drama',\t'best performance by an actor in a motion picture - comedy or musical','best performance by an actor in a supporting role in a series, mini-series or motion picture made for television','best performance by an actress in a supporting role in a motion picture','best performance by an actor in a mini-series or motion picture made for television','best performance by an actress in a mini-series or motion picture made for television','best performance by an actor in a motion picture - drama', 'best performance by an actor in a television series - drama','best performance by an actor in a television series - comedy or musical']\n",
        "people_keywords = 'actor|actress|supporting|role|performance|director'\n",
        "series_keywords = 'series|tv|television'\n",
        "MOVIE_AWARDS = ['best screenplay - motion picture','best television series - comedy or musical','best original song - motion picture','best motion picture - comedy or musical','best foreign language film','best mini-series or motion picture made for television','best motion picture - drama','best television series - drama','best animated feature film','best original score - motion picture',]"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiCa5hmQfaY2"
      },
      "source": [
        "def open_jsonfile(data_path = 'sample_data/gg2013.json'):\n",
        "  file_ = open(data_path)\n",
        "  data = json.load(file_)\n",
        "  return data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADgY-T1LfhHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95366cb3-5501-420b-88b0-7cfc03b271e2"
      },
      "source": [
        "def clean_award_name(award_name):\n",
        "  #removes stopwords from award name and returns key words in award name as list\n",
        "  award_name = award_name.lower()\n",
        "  cleaned_award = []\n",
        "  split = award_name.split()\n",
        "  for word in split:\n",
        "    if word not in mystop_words and word not in ['motion','picture','series,','series','role']:  # Many words are irrelevant, removed with list of stopwords\n",
        "      cleaned_award.append(word)\n",
        "      if word == 'television':  # Usually television is shortened to tv, want to account for both\n",
        "        cleaned_award.append('tv')\n",
        "  return cleaned_award\n",
        "##############testing function#######################\n",
        "for award_name in PEOPLE_AWARDS:\n",
        "  print(clean_award_name(award_name))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['best', 'director']\n",
            "['best', 'actress', 'television', 'tv', 'comedy', 'musical']\n",
            "['best', 'actor', 'supporting']\n",
            "['best', 'actress', 'supporting', 'mini-series', 'television', 'tv']\n",
            "['best', 'actress', 'comedy', 'musical']\n",
            "['best', 'actress', 'television', 'tv', 'drama']\n",
            "['best', 'actress', 'drama']\n",
            "['best', 'actor', 'comedy', 'musical']\n",
            "['best', 'actor', 'supporting', 'mini-series', 'television', 'tv']\n",
            "['best', 'actress', 'supporting']\n",
            "['best', 'actor', 'mini-series', 'television', 'tv']\n",
            "['best', 'actress', 'mini-series', 'television', 'tv']\n",
            "['best', 'actor', 'drama']\n",
            "['best', 'actor', 'television', 'tv', 'drama']\n",
            "['best', 'actor', 'television', 'tv', 'comedy', 'musical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-jMDJZLFieg4",
        "outputId": "45691c6e-98cd-4e33-e283-b13a27b61254"
      },
      "source": [
        "def award_relevant_tweets(tweet_data, award_keywords):\n",
        "  relevant_tweets = []\n",
        "  for tweet in tweet_data:\n",
        "    text = tweet['text']\n",
        "    text = text.lower()\n",
        "    tweet_text = tweet['text']\n",
        "    tweet_text.replace('-',' ')\n",
        "    tweet_text.replace('/',' ')\n",
        "    if 'rt @' in text:\n",
        "      continue\n",
        "    if 'tv' in award_keywords and not re.search('tv|television|series',text):\n",
        "      continue\n",
        "    if 'tv' not in award_keywords and re.search('tv|television|series',text):\n",
        "      continue\n",
        "    check = 0\n",
        "    for key_word in award_keywords:\n",
        "      if key_word not in text:\n",
        "        check +=1\n",
        "    if 'tv' in award_keywords:\n",
        "      if check <2:\n",
        "        relevant_tweets.append(tweet_text)\n",
        "    else:\n",
        "      if check ==0:\n",
        "        relevant_tweets.append(tweet_text)\n",
        "      \"\"\"else:\n",
        "        if winner.lower() in text:\n",
        "          relevant_tweets.append(tweet['text'])\"\"\"\n",
        "  return relevant_tweets\n",
        "\n",
        "######testing function###########\n",
        "\"\"\"data = open_jsonfile(data_path = 'sample_data/gg2013.json')\n",
        "award_keywords = clean_award_name('best performance by an actress in a motion picture - drama')\n",
        "rel_tweets = award_relevant_tweets(data,award_keywords,winner = 'Jessica Chastain')\n",
        "for rel_tweet in rel_tweets:\n",
        "  print(rel_tweet)\"\"\"\n"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"data = open_jsonfile(data_path = 'sample_data/gg2013.json')\\naward_keywords = clean_award_name('best performance by an actress in a motion picture - drama')\\nrel_tweets = award_relevant_tweets(data,award_keywords,winner = 'Jessica Chastain')\\nfor rel_tweet in rel_tweets:\\n  print(rel_tweet)\""
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQqm1GOinO_Y"
      },
      "source": [
        "def remove_stop_words(small_tweet,mystop_words = mystop_words):\n",
        "  small_tweet = small_tweet.lower()\n",
        "  good_tweet = []\n",
        "  split = small_tweet.split()\n",
        "  for word in split:\n",
        "    if re.search('http',word.lower()):\n",
        "      continue\n",
        "    if word.lower() not in mystop_words:\n",
        "      good_tweet.append(word)\n",
        "  return(' '.join(good_tweet))\n",
        "\n",
        "###########testing function##########\n",
        "#small_tweet = 'Golden Globes: Winner for Best Supporting Actor in a Motion Picture is Christoph Waltz for \"Django Unchained\"'\n",
        "#print(remove_stop_words('small_tweet here is the link https://asfasdfsd.com'))"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snQDwHnZnig3"
      },
      "source": [
        "def add_to_dictionary(potential_nominees, person_ents,award_keywords,weightage):\n",
        "  #small_tweet = re.sub('#([a-zA-Z0-9_]{1,50})', '', small_tweet)\n",
        "  if len(person_ents) == 0:\n",
        "    return\n",
        "  for entity in person_ents:\n",
        "    entity = remove_stop_words(entity)\n",
        "    check = 0\n",
        "    \"\"\"for token in entity.split():\n",
        "      if token in award_keywords:\n",
        "        check +=1\n",
        "    if check == len(entity.split()):\n",
        "      continue\"\"\"\n",
        "    if len(entity.replace(' ','')) == 0:\n",
        "      continue\n",
        "    #entity = entity.replace('#',' ') #removing hashtags symbols\n",
        "    #entity = re.sub('@([a-zA-Z0-9_]{1,50})', '', entity)\n",
        "    #entity = re.sub(r'[^\\w\\s]','',entity) # removing punctuation\n",
        "    if entity in potential_nominees.keys():\n",
        "      potential_nominees[entity] += weightage\n",
        "    else:\n",
        "      potential_nominees[entity] = weightage"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up_DenupBddk",
        "outputId": "3207fc5c-2138-4d64-af86-a89d5b250f03"
      },
      "source": [
        "array = ['STEVEN','SPIELBERG','iamgod']\n",
        "for i in range(len(array)):\n",
        "  if array[i].isupper():\n",
        "    array[i] = array[i].capitalize()\n",
        "print(array)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Steven', 'Spielberg', 'iamgod']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5OjRZ5aq2tX"
      },
      "source": [
        "#text = 'Argo man, what a film. Ben was snubbed for best director at the oscars and Steven did not even win. ridiculous  #goldenglobes'\n",
        "\n",
        "def return_persons_2_tokens(text,award_keywords):\n",
        "  array = []\n",
        "  people = []\n",
        "  #if 'spielberg' in text.lower():\n",
        "   # print(text)\n",
        "  #if len(text.replace(' ','')) == 0:\n",
        "  #  return people\n",
        "  text = text.replace('#([a-zA-Z0-9_]{1,50})','') #removing hashtags symbols\n",
        "  text = re.sub('@([a-zA-Z0-9_]{1,50})', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  for i in range(len(tokens)):\n",
        "    if tokens[i].isupper():\n",
        "      tokens[i] = tokens[i].capitalize()\n",
        "  pos = pos_tag(tokens)\n",
        "  ner_tags = ne_chunk(pos, binary=False)\n",
        "  entity = \"\"\n",
        "  for tree in ner_tags.subtrees(filter=lambda t: t.label() == \"PERSON\"):\n",
        "    for leaf in tree.leaves():\n",
        "      if leaf[0].lower() not in award_keywords:\n",
        "        array.append(leaf[0])\n",
        "    person = ' '.join(array)\n",
        "    person = remove_stop_words(person)\n",
        "    if len(person.split()) == 2:\n",
        "      people.append(person)\n",
        "  return people\n",
        "#print(return_persons_1_tokens(text))"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufKNBnpA5lyb"
      },
      "source": [
        "def return_persons_1_tokens(text):\n",
        "  array = []\n",
        "  people = []\n",
        "  if len(text.replace(' ','')) == 0:\n",
        "    return people\n",
        "  entity = entity.replace('#',' ') #removing hashtags symbols\n",
        "  small_tweet = re.sub('@([a-zA-Z0-9_]{1,50})', '', entity)\n",
        "  tokens = word_tokenize(text)\n",
        "  pos = pos_tag(tokens)\n",
        "  ner_tags = ne_chunk(pos, binary=False)\n",
        "  entity = \"\"\n",
        "  for tree in ner_tags.subtrees(filter=lambda t: t.label() == \"PERSON\"):\n",
        "    for leaf in tree.leaves():\n",
        "      array.append(leaf[0])\n",
        "    if len(array) == 2:\n",
        "      person = ' '.join(array)\n",
        "      people.append(person)\n",
        "    array = []\n",
        "  return people"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PyXBSaun52E"
      },
      "source": [
        "def populate_potential_people_nominees(filtered_tweets,award_keywords):\n",
        "  stretch = 3\n",
        "  potential_nominees = {}\n",
        "  prior_keywords = ['won','win','deserve','deserving','deserved','nomination','nominated','snubbed','better','is up for']\n",
        "  posterior_keywords = ['nominee','deserved award for','preferred','goes to','over','would have been','awarded to','should have','go to','should have been']\n",
        "  biside_keywords = ['nom','beat','rob','beats','winner','beating','loser','losers','wins over','stole','loses','lost']\n",
        "  negative_indicating_keywords = 'nominated|nominee|nomination|nominations|nom'\n",
        "  negative_keywords = 'should have|did not|should\\'ve|not|reject|didn\\'t'\n",
        "  for tweet in filtered_tweets:\n",
        "    text = tweet.lower()\n",
        "    check = 0\n",
        "    if re.search(negative_indicating_keywords,text) and re.search(negative_keywords,text):\n",
        "      continue\n",
        "    for keyword in prior_keywords:\n",
        "      if keyword in text:\n",
        "        check = 1\n",
        "        small_tweet = tweet[:re.search(keyword,text).start()]\n",
        "        tokens = small_tweet.split()\n",
        "        if len(tokens) == 0:\n",
        "          continue\n",
        "        elif len(tokens) <= stretch:\n",
        "          small_tweet = ' '.join(tokens)\n",
        "          #small_tweet = remove_stop_words(small_tweet)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "        else:\n",
        "          small_tweet = ' '.join(tokens[-stretch:])\n",
        "          #small_tweet = remove_stop_words(small_tweet)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "          small_tweet = ' '.join(tokens[0:-stretch])\n",
        "          #small_tweet = remove_stop_words(small_tweet)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 10)\n",
        "        #person_ents = return_persons_2_tokens(small_tweet)\n",
        "        #add_to_dictionary(potential_nominees,person_ents,weightage = 20)\n",
        "    for keyword in posterior_keywords:\n",
        "      if keyword in text:\n",
        "        check = 1\n",
        "        small_tweet = tweet[re.search(keyword,text).start():]\n",
        "        tokens = small_tweet.split()\n",
        "        if len(tokens) <= 1:\n",
        "          continue\n",
        "        tokens = tokens[1:]\n",
        "        if len(tokens) <= stretch:\n",
        "          small_tweet = ' '.join(tokens)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "        else:\n",
        "          small_tweet = ' '.join(tokens[0:stretch])\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "          small_tweet = ' '.join(tokens[stretch:])\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 10)\n",
        "        #small_tweet = ' '.join(tokens)\n",
        "        #person_ents = return_persons_2_tokens(small_tweet)\n",
        "        #add_to_dictionary(potential_nominees,person_ents,weightage = 20)\n",
        "    for keyword in biside_keywords:\n",
        "      if keyword in text:\n",
        "        check = 1\n",
        "        small_tweet_left = tweet[:re.search(keyword,text).start()]\n",
        "        small_tweet_right = tweet[re.search(keyword,text).start():]\n",
        "        tokens_left = small_tweet_left.split()\n",
        "        tokens_right = small_tweet_right.split()\n",
        "        if len(tokens_left) > 0:\n",
        "          if len(tokens_left) <= stretch:\n",
        "            small_tweet_left = ' '.join(tokens_left)\n",
        "            person_ents_left = return_persons_2_tokens(small_tweet_left,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_left,award_keywords,weightage = 20)\n",
        "          else:\n",
        "            small_tweet_left = ' '.join(tokens_left[-stretch:])\n",
        "            person_ents_left = return_persons_2_tokens(small_tweet_left,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_left,award_keywords,weightage = 20)\n",
        "            small_tweet_left = ' '.join(tokens_left[0:-stretch])\n",
        "            person_ents_left = return_persons_2_tokens(small_tweet_left,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_left,award_keywords,weightage = 10)\n",
        "        if len(tokens_right) > 1:\n",
        "          tokens_right = tokens_right[1:]\n",
        "          if len(tokens_right) <= stretch:\n",
        "            small_tweet_right = ' '.join(tokens_right)\n",
        "            person_ents_right = return_persons_2_tokens(small_tweet_right,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_right,award_keywords,weightage = 20)\n",
        "          else:\n",
        "            small_tweet_right = ' '.join(tokens_right[0:stretch])\n",
        "            person_ents_right = return_persons_2_tokens(small_tweet_right,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_right,award_keywords,weightage = 20)\n",
        "            small_tweet_right = ' '.join(tokens_right[stretch:])\n",
        "            person_ents_right = return_persons_2_tokens(small_tweet_right,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_right,award_keywords,weightage = 10)\n",
        "        #person_ents_left = return_persons_2_tokens(small_tweet_left)\n",
        "        #person_ents_right = return_persons_2_tokens(small_tweet_right)\n",
        "        #add_to_dictionary(potential_nominees,person_ents_left,weightage = 20)\n",
        "        #add_to_dictionary(potential_nominees,person_ents_right,weightage = 20)\n",
        "    if check == 0:\n",
        "      person_ents = return_persons_2_tokens(tweet,award_keywords)\n",
        "      add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 10)\n",
        "  return potential_nominees\n"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEvo2zxZTdDV",
        "outputId": "1a4cf27c-e77c-4f1c-dcda-d4c602c859f1"
      },
      "source": [
        "array = [1,2,3,4,5,6,4,5,6]\n",
        "print(array[0:-3])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XD1WkDa5seS"
      },
      "source": [
        "def get_cosine(vec1, vec2):\n",
        "    # print vec1, vec2\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "    return Counter(WORD.findall(text))\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a = text_to_vector(a.strip().lower())\n",
        "    b = text_to_vector(b.strip().lower())\n",
        "\n",
        "    return get_cosine(a, b)\n",
        "\n",
        "##################testing function###############\n",
        "#print(cosine_similarity('steven ','steven speilberg'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J13plzmG51rI"
      },
      "source": [
        "def char_similarity(a,b):\n",
        "  final_similarity = 0\n",
        "  a = a.lower()\n",
        "  b = b.lower()\n",
        "  a_tokens = a.split()\n",
        "  b_tokens = b.split()\n",
        "  for a_token in a_tokens:\n",
        "    for b_token in b_tokens:\n",
        "      similarity = 0\n",
        "      if len(a_token) > len(b_token):\n",
        "        bigger_token = a_token\n",
        "        smaller_token = b_token\n",
        "      else:\n",
        "        bigger_token = b_token\n",
        "        smaller_token = a_token\n",
        "      for i in range(len(smaller_token)):\n",
        "        if smaller_token[i] == bigger_token[i]:\n",
        "          similarity += 1\n",
        "      if final_similarity < similarity/len(smaller_token):\n",
        "        final_similarity = similarity/len(smaller_token)\n",
        "  return final_similarity\n",
        "\n",
        "##############testing function###################\n",
        "#print(char_similarity('ang lee','anger'))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpkaMqtC7-UU",
        "outputId": "5bb8801d-5a89-4374-ad51-b5221ba858de"
      },
      "source": [
        "def merge_potential_nominees(potential_nominees):\n",
        "  compressed_nominees = {}\n",
        "  potential_nominees = sorted(potential_nominees.items(), key = lambda k: -k[1])\n",
        "  potential_nominees = dict(potential_nominees)\n",
        "  for key1 in potential_nominees.keys():\n",
        "    if len(compressed_nominees) == 0:\n",
        "      compressed_nominees[key1] = potential_nominees[key1]\n",
        "    else:\n",
        "      for key2 in list(compressed_nominees.keys()):\n",
        "        #if cosine_similarity(key1,key2) >= 0.6:\n",
        "        if len(difflib.get_close_matches(key1,[key2],cutoff = 0.5))==1:\n",
        "          compressed_nominees[key2] += potential_nominees[key1]\n",
        "          break\n",
        "        else:\n",
        "          if key2 == list(compressed_nominees.keys())[-1]:\n",
        "            compressed_nominees[key1] = potential_nominees[key1]\n",
        "  return compressed_nominees\n",
        "\n",
        "##############testing function###################\n",
        "#tweet_data = open_jsonfile(data_path = 'sample_data/gg2013.json')\n",
        "#award_keywords = clean_award_name(\"best supporting actress in a motion picture\")\n",
        "#relevant_tweets = award_relevant_tweets(tweet_data, award_keywords)\n",
        "#potential_nominees = populate_potential_movie_nominees(relevant_tweets)\n",
        "#merged_nominees = merge_potential_nominees(potential_nominees)\n",
        "#for key in merged_nominees.keys():\n",
        "#  print(key,merged_nominees[key])\n",
        "print(difflib.get_close_matches('ang lee',['mind blo'],cutoff = 0.4))"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mind blo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN-4Td4c6Rbq",
        "outputId": "6b865890-5894-4816-a437-487d99f522ea"
      },
      "source": [
        "def check_on_imdb(merged_potential_nominees):\n",
        "  merged_potential_nominees = sorted(merged_potential_nominees.items(), key = lambda k: -k[1])\n",
        "  merged_potential_nominees = dict(merged_potential_nominees)\n",
        "  result_nominees = []\n",
        "  count = 0\n",
        "  for key in merged_potential_nominees.keys():\n",
        "    if len(key.split()) <= 1:\n",
        "      continue\n",
        "    persons_identified = ia.search_person(key)\n",
        "    if len(persons_identified) != 0:\n",
        "      #print(key,persons_identified[0])\n",
        "      if (cosine_similarity(key,persons_identified[0]['name'])+char_similarity(key,persons_identified[0]['name']))/2 >= 0.7:\n",
        "        if len(result_nominees) == 0:\n",
        "          result_nominees.append(persons_identified[0]['name'])\n",
        "          count += 1\n",
        "        elif persons_identified[0]['name'] not in result_nominees:\n",
        "          result_nominees.append(persons_identified[0]['name'])\n",
        "          count += 1\n",
        "      if count == 5 :\n",
        "        break\n",
        "  return result_nominees\n",
        "################testing function####################\n",
        "#result_nominees = check_on_imdb(merged_nominees)\n",
        "print(ia.search_person('tommy lee')[0]['name'])"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tommy Lee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbRrKHs_rk7"
      },
      "source": [
        "def find_nominees(award_name):\n",
        "  #open the json file of tweets\n",
        "  tweet_data = open_jsonfile()\n",
        "  #clean the award name and take it as list of tokens\n",
        "  award_keywords = clean_award_name(award_name)\n",
        "  #find all tweets relevant to this award name\n",
        "  filtered_tweets = award_relevant_tweets(tweet_data,award_keywords)\n",
        "  #for tweet in filtered_tweets:\n",
        "  #  print(tweet)\n",
        "  #print(filtered_tweets)\n",
        "  #find potential nominees from relevant tweets\n",
        "  potential_nominees = populate_potential_people_nominees(filtered_tweets,award_keywords)\n",
        "  #print(potential_nominees)\n",
        "  #print(potential_nominees)\n",
        "  #merge potential nominees if there are various version of same nominees\n",
        "  merged_potential_nominees = merge_potential_nominees(potential_nominees)\n",
        "  print(merged_potential_nominees)\n",
        "  #print(merged_potential_nominees)\n",
        "  #query imdb for best five results\n",
        "  results = check_on_imdb(merged_potential_nominees)\n",
        "  #return top five results\n",
        "  return results\n",
        "#winners = ['Ben Affleck','Lena Dunham']\n"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_1EO3-bCnQI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_51CdGAkF9",
        "outputId": "87743fa9-6ef8-4843-a1ff-96bbc79bbc9b"
      },
      "source": [
        "find_nominees('best director - motion picture')"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ben affleck': 2800, 'golden globes': 200, 'oscar snub': 110, 'ang lee': 30, 'jared leto': 20, 'quentin tarantino': 30, 'halle berry': 20, 'steven spielberg': 20, 'mind blo': 20, 'watch ben': 30, 'jennifer garner': 20, 'argo takes': 30, 'motion picture': 30, 'speilberg lincoln': 20, 'joe wright': 10, 'jodie foster': 10, 'matt damon': 10, 'django argo': 20, 'jon hamm': 10}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ben Affleck',\n",
              " 'Golden Glory Team',\n",
              " 'Oscar Snel',\n",
              " 'Ang Lee',\n",
              " 'Quentin Tarantino']"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdC5t7Q08c0h",
        "outputId": "3b1e7184-7e92-4bc9-a0be-beec44469c89"
      },
      "source": [
        "for award_name in PEOPLE_AWARDS:\n",
        "  print('---------------------------------')\n",
        "  print(award_name)\n",
        "  print(find_nominees(award_name))"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "best director - motion picture\n",
            "{'ben affleck': 2800, 'golden globes': 200, 'oscar snub': 110, 'ang lee': 30, 'jared leto': 20, 'quentin tarantino': 30, 'halle berry': 20, 'steven spielberg': 20, 'mind blo': 20, 'watch ben': 30, 'jennifer garner': 20, 'argo takes': 30, 'motion picture': 30, 'speilberg lincoln': 20, 'joe wright': 10, 'jodie foster': 10, 'matt damon': 10, 'django argo': 20, 'jon hamm': 10}\n",
            "['Ben Affleck', 'Golden Glory Team', 'Oscar Snel', 'Ang Lee', 'Quentin Tarantino']\n",
            "---------------------------------\n",
            "best performance by an actress in a television series - comedy or musical\n",
            "{'lena dunham': 190, 'jennifer lawrence': 20}\n",
            "['Lena Dunham', 'Jennifer Lawrence']\n",
            "---------------------------------\n",
            "best performance by an actor in a supporting role in a motion picture\n",
            "{'christoph waltz': 1680, 'django unchained': 110, 'golden globes': 100, 'tommy lee': 40, 'alan arkin': 20, 'lee jones': 20, 'leonardo dicaprio': 30, 'garrett hedlund': 20, 'daniel lewis': 10, 'mimin movie': 10, 'les miserable': 10, 'george w': 10}\n",
            "['Christoph Waltz', 'Golden Glory Team', 'Tommy Lee', 'Leonardo DiCaprio', 'Alan Arkin']\n",
            "---------------------------------\n",
            "best performance by an actress in a supporting role in a series, mini-series or motion picture made for television\n",
            "{'maggie smith': 40}\n",
            "['Maggie Smith']\n",
            "---------------------------------\n",
            "best performance by an actress in a motion picture - comedy or musical\n",
            "{'jennifer lawrence': 940, 'hathaway waltz': 90, 'les misérables': 30, 'naomi watts': 10, 'linings playbook': 10, 'motion picture': 10, 'leana dunham': 20}\n",
            "['Jennifer Lawrence', 'Les Misérables', 'Lena Dunham', 'Naomi Watts', 'Silver Linings Playbook']\n",
            "---------------------------------\n",
            "best performance by an actress in a television series - drama\n",
            "{'claire danes': 340, 'lea michele': 20, 'damien lewis': 10, 'jessica chastain': 10}\n",
            "['Claire Danes', 'Lea Michele', 'Damien Lewis', 'Jessica Chastain']\n",
            "---------------------------------\n",
            "best performance by an actress in a motion picture - drama\n",
            "{'jessica chastain': 1870, 'jennifer lawrence': 40, 'golden globe': 60, 'naomi watts': 30, 'maggie smith': 20, 'michelle dockery': 30, 'anne hathaway': 20, 'clare danes': 50, 'les mis': 10}\n",
            "['Jessica Chastain', 'Golden Glory Team', 'Claire Danes', 'Jennifer Lawrence', 'Naomi Watts']\n",
            "---------------------------------\n",
            "best performance by an actor in a motion picture - comedy or musical\n",
            "{'hugh jackman': 870, 'les miserables': 130, 'golden globes': 40, 'louis louie': 10, 'jack black': 10}\n",
            "['Hugh Jackman', 'Les Miserables', 'Golden Glory Team', 'Louis Lombardi', 'Jack Black']\n",
            "---------------------------------\n",
            "best performance by an actor in a supporting role in a series, mini-series or motion picture made for television\n",
            "{'ed harris': 40}\n",
            "['Ed Harris']\n",
            "---------------------------------\n",
            "best performance by an actress in a supporting role in a motion picture\n",
            "{'anne hathaway': 1700, 'maggie smith': 170, 'les miserables': 190, 'jennifer lawrence': 50, 'golden globes': 40, 'motion picture': 40, 'sally field': 30, 'congratz anne': 30, 'nicole kidman': 10, 'yesss anne': 10}\n",
            "['Anne Hathaway', 'Les Miserables', 'Maggie Smith', 'Jennifer Lawrence', 'Golden Glory Team']\n",
            "---------------------------------\n",
            "best performance by an actor in a mini-series or motion picture made for television\n",
            "{'kevin costner': 140, 'ed harris': 50}\n",
            "['Kevin Costner', 'Ed Harris']\n",
            "---------------------------------\n",
            "best performance by an actress in a mini-series or motion picture made for television\n",
            "{'julianne moore': 160, 'maggie smith': 40, 'nicole kidman': 10}\n",
            "['Julianne Moore', 'Maggie Smith', 'Nicole Kidman']\n",
            "---------------------------------\n",
            "best performance by an actor in a motion picture - drama\n",
            "{'daniel lewis': 470, 'christoph waltz': 100, 'motion picture': 50, 'golden globes': 40, 'leo dicaprio': 20, 'lewis lincoln': 20, 'okay jokes': 10, 'tony kushner': 10, 'hugh jackman': 10}\n",
            "['Daniel Lewis', 'Christoph Waltz', 'Motion Picture Magic', 'Golden Glory Team', 'Leonardo DiCaprio']\n",
            "---------------------------------\n",
            "best performance by an actor in a television series - drama\n",
            "{'damian lewis': 280, 'bill clinton': 20, 'connie britton': 10, 'lewinsky scandal': 10}\n",
            "['Damian Lewis', 'Bill Clinton', 'Connie Britton']\n",
            "---------------------------------\n",
            "best performance by an actor in a television series - comedy or musical\n",
            "{'series cheadle': 20, 'jim parsons': 10}\n",
            "['Jim Parsons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wADXUckFD9oI"
      },
      "source": [
        "tweet_data = open_jsonfile(data_path = 'sample_data/gg2013.json')\n",
        "#print(tweet_data[0])\n",
        "for data in tweet_data:\n",
        "  if 'rt @' in data['text'].lower():\n",
        "    continue\n",
        "  if 'don cheadle' in data['text'].lower() and re.search('best',data['text'].lower())and re.search('actor',data['text'].lower()) and re.search('tv|television',data['text'].lower()) :\n",
        "    print (data['text'])\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}