{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "People nominees v1.3",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_F0N2JS3Vbo",
        "outputId": "332b9e1d-2813-458d-84d1-63823aaa633d"
      },
      "source": [
        "pip install git+https://github.com/alberanid/imdbpy"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/alberanid/imdbpy\n",
            "  Cloning https://github.com/alberanid/imdbpy to /tmp/pip-req-build-oru2vmzb\n",
            "  Running command git clone -q https://github.com/alberanid/imdbpy /tmp/pip-req-build-oru2vmzb\n",
            "Requirement already satisfied: SQLAlchemy in /usr/local/lib/python3.7/dist-packages (from IMDbPY==2021.10.24) (1.4.25)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from IMDbPY==2021.10.24) (4.2.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy->IMDbPY==2021.10.24) (4.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy->IMDbPY==2021.10.24) (1.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy->IMDbPY==2021.10.24) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy->IMDbPY==2021.10.24) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIFQutooc287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b613da1-aede-4ab0-f51a-af2082c9a15d"
      },
      "source": [
        "import json\n",
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "import difflib\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('stopwords')\n",
        "from imdb import IMDb\n",
        "import math\n",
        "from collections import Counter\n",
        "WORD = re.compile(r'\\w+')\n",
        "ia = IMDb()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqC2izeAZjZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d348012-acd2-4af2-e21b-90f15b6116b8"
      },
      "source": [
        "mystop_words = stopwords.words('english')\n",
        "mystop_words.extend(['performance','made','-','congrats','congratulations','got','knows','well','well-','hell','yeah','go'])\n",
        "mystop_words.remove('don')\n",
        "print(mystop_words)\n",
        "PEOPLE_AWARDS = ['best director - motion picture','best performance by an actress in a television series - comedy or musical','best performance by an actor in a supporting role in a motion picture','best performance by an actress in a supporting role in a series, mini-series or motion picture made for television','best performance by an actress in a motion picture - comedy or musical','best performance by an actress in a television series - drama','best performance by an actress in a motion picture - drama',\t'best performance by an actor in a motion picture - comedy or musical','best performance by an actor in a supporting role in a series, mini-series or motion picture made for television','best performance by an actress in a supporting role in a motion picture','best performance by an actor in a mini-series or motion picture made for television','best performance by an actress in a mini-series or motion picture made for television','best performance by an actor in a motion picture - drama', 'best performance by an actor in a television series - drama','best performance by an actor in a television series - comedy or musical']\n",
        "people_keywords = 'actor|actress|supporting|role|performance|director'\n",
        "series_keywords = 'series|tv|television'\n",
        "MOVIE_AWARDS = ['best screenplay - motion picture','best television series - comedy or musical','best original song - motion picture','best motion picture - comedy or musical','best foreign language film','best mini-series or motion picture made for television','best motion picture - drama','best television series - drama','best animated feature film','best original score - motion picture',]\n",
        "ceremony_name = 'goldenglobes'"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'performance', 'made', '-', 'congrats', 'congratulations', 'got', 'knows', 'well', 'well-', 'hell', 'yeah', 'go']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiCa5hmQfaY2"
      },
      "source": [
        "def open_jsonfile(data_path = 'sample_data/gg2013.json'):\n",
        "  file_ = open(data_path)\n",
        "  data = json.load(file_)\n",
        "  return data"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADgY-T1LfhHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4edc5173-6bf5-416b-df48-1e7d8de7f006"
      },
      "source": [
        "def clean_award_name(award_name):\n",
        "  #removes stopwords from award name and returns key words in award name as list\n",
        "  award_name = award_name.lower()\n",
        "  cleaned_award = []\n",
        "  split = award_name.split()\n",
        "  for word in split:\n",
        "    if word not in mystop_words and word not in ['motion','picture','series,','series','role']:  # Many words are irrelevant, removed with list of stopwords\n",
        "      cleaned_award.append(word)\n",
        "      if word == 'television':  # Usually television is shortened to tv, want to account for both\n",
        "        cleaned_award.append('tv')\n",
        "  return cleaned_award\n",
        "##############testing function#######################\n",
        "for award_name in PEOPLE_AWARDS:\n",
        "  print(clean_award_name(award_name))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['best', 'director']\n",
            "['best', 'actress', 'television', 'tv', 'comedy', 'musical']\n",
            "['best', 'actor', 'supporting']\n",
            "['best', 'actress', 'supporting', 'mini-series', 'television', 'tv']\n",
            "['best', 'actress', 'comedy', 'musical']\n",
            "['best', 'actress', 'television', 'tv', 'drama']\n",
            "['best', 'actress', 'drama']\n",
            "['best', 'actor', 'comedy', 'musical']\n",
            "['best', 'actor', 'supporting', 'mini-series', 'television', 'tv']\n",
            "['best', 'actress', 'supporting']\n",
            "['best', 'actor', 'mini-series', 'television', 'tv']\n",
            "['best', 'actress', 'mini-series', 'television', 'tv']\n",
            "['best', 'actor', 'drama']\n",
            "['best', 'actor', 'television', 'tv', 'drama']\n",
            "['best', 'actor', 'television', 'tv', 'comedy', 'musical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-jMDJZLFieg4",
        "outputId": "8e9ada2e-f350-4578-9c3a-7c1b16e1e743"
      },
      "source": [
        "def award_relevant_tweets(tweet_data, award_keywords):\n",
        "  relevant_tweets = []\n",
        "  for tweet in tweet_data:\n",
        "    text = tweet['text']\n",
        "    text = text.lower()\n",
        "    tweet_text = tweet['text']\n",
        "    tweet_text.replace('-',' ')\n",
        "    tweet_text.replace('/',' ')\n",
        "    if 'rt @' in text:\n",
        "      continue\n",
        "    if 'tv' in award_keywords and not re.search('tv|television|series',text):\n",
        "      continue\n",
        "    if 'tv' not in award_keywords and re.search('tv|television|series',text):\n",
        "      continue\n",
        "    if 'supporting' in award_keywords and not re.search('supporting',text):\n",
        "      continue\n",
        "    check = 0\n",
        "    for key_word in award_keywords:\n",
        "      if key_word not in text:\n",
        "        check +=1\n",
        "    if 'tv' in award_keywords:\n",
        "      if check <2:\n",
        "        relevant_tweets.append(tweet_text)\n",
        "    else:\n",
        "      if check ==0:\n",
        "        relevant_tweets.append(tweet_text)\n",
        "      \"\"\"else:\n",
        "        if winner.lower() in text:\n",
        "          relevant_tweets.append(tweet['text'])\"\"\"\n",
        "  return relevant_tweets\n",
        "\n",
        "######testing function###########\n",
        "\"\"\"data = open_jsonfile(data_path = 'sample_data/gg2013.json')\n",
        "award_keywords = clean_award_name('best performance by an actress in a motion picture - drama')\n",
        "rel_tweets = award_relevant_tweets(data,award_keywords,winner = 'Jessica Chastain')\n",
        "for rel_tweet in rel_tweets:\n",
        "  print(rel_tweet)\"\"\"\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"data = open_jsonfile(data_path = 'sample_data/gg2013.json')\\naward_keywords = clean_award_name('best performance by an actress in a motion picture - drama')\\nrel_tweets = award_relevant_tweets(data,award_keywords,winner = 'Jessica Chastain')\\nfor rel_tweet in rel_tweets:\\n  print(rel_tweet)\""
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQqm1GOinO_Y"
      },
      "source": [
        "def remove_stop_words(small_tweet,mystop_words = mystop_words):\n",
        "  small_tweet = small_tweet.lower()\n",
        "  good_tweet = []\n",
        "  split = small_tweet.split()\n",
        "  for word in split:\n",
        "    if re.search('http',word.lower()):\n",
        "      continue\n",
        "    if word.lower() not in mystop_words:\n",
        "      good_tweet.append(word)\n",
        "  return(' '.join(good_tweet))\n",
        "\n",
        "###########testing function##########\n",
        "#small_tweet = 'Golden Globes: Winner for Best Supporting Actor in a Motion Picture is Christoph Waltz for \"Django Unchained\"'\n",
        "#print(remove_stop_words('small_tweet here is the link https://asfasdfsd.com'))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snQDwHnZnig3"
      },
      "source": [
        "def add_to_dictionary(potential_nominees, person_ents,award_keywords,weightage):\n",
        "  #small_tweet = re.sub('#([a-zA-Z0-9_]{1,50})', '', small_tweet)\n",
        "  if len(person_ents) == 0:\n",
        "    return\n",
        "  for entity in person_ents:\n",
        "    entity = remove_stop_words(entity)\n",
        "    check = 0\n",
        "    \"\"\"for token in entity.split():\n",
        "      if token in award_keywords:\n",
        "        check +=1\n",
        "    if check == len(entity.split()):\n",
        "      continue\"\"\"\n",
        "    if len(entity.replace(' ','')) == 0:\n",
        "      continue\n",
        "    #entity = entity.replace('#',' ') #removing hashtags symbols\n",
        "    #entity = re.sub('@([a-zA-Z0-9_]{1,50})', '', entity)\n",
        "    #entity = re.sub(r'[^\\w\\s]','',entity) # removing punctuation\n",
        "    if entity in potential_nominees.keys():\n",
        "      potential_nominees[entity] += weightage\n",
        "    else:\n",
        "      potential_nominees[entity] = weightage"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up_DenupBddk",
        "outputId": "3713116a-7d18-4c95-ae69-1dce82b0ee22"
      },
      "source": [
        "array = ['STEVEN','SPIELBERG','iamgod']\n",
        "for i in range(len(array)):\n",
        "  if array[i].isupper():\n",
        "    array[i] = array[i].capitalize()\n",
        "print(array)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Steven', 'Spielberg', 'iamgod']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5OjRZ5aq2tX"
      },
      "source": [
        "#text = 'Argo man, what a film. Ben was snubbed for best director at the oscars and Steven did not even win. ridiculous  #goldenglobes'\n",
        "\n",
        "def return_persons_2_tokens(text,award_keywords):\n",
        "  array = []\n",
        "  people = []\n",
        "  #if 'spielberg' in text.lower():\n",
        "   # print(text)\n",
        "  #if len(text.replace(' ','')) == 0:\n",
        "  #  return people\n",
        "  text = text.replace('#([a-zA-Z0-9_]{1,50})','') #removing hashtags symbols\n",
        "  text = re.sub('@([a-zA-Z0-9_]{1,50})', '', text)\n",
        "  tokens = word_tokenize(text)\n",
        "  for i in range(len(tokens)):\n",
        "    if tokens[i].isupper():\n",
        "      tokens[i] = tokens[i].capitalize()\n",
        "  pos = pos_tag(tokens)\n",
        "  ner_tags = ne_chunk(pos, binary=False)\n",
        "  entity = \"\"\n",
        "  for tree in ner_tags.subtrees(filter=lambda t: t.label() == \"PERSON\"):\n",
        "    for leaf in tree.leaves():\n",
        "      if not re.search(leaf[0].lower(),ceremony_name) and leaf[0].lower() not in award_keywords and leaf[0].lower() not in ['motion','picture','series,','series','role']:\n",
        "        array.append(leaf[0])\n",
        "    person = ' '.join(array)\n",
        "    person = remove_stop_words(person)\n",
        "    if len(person.split()) == 2:\n",
        "      people.append(person)\n",
        "  return people\n",
        "#print(return_persons_1_tokens(text))"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufKNBnpA5lyb"
      },
      "source": [
        "def return_persons_1_tokens(text):\n",
        "  array = []\n",
        "  people = []\n",
        "  if len(text.replace(' ','')) == 0:\n",
        "    return people\n",
        "  entity = entity.replace('#',' ') #removing hashtags symbols\n",
        "  small_tweet = re.sub('@([a-zA-Z0-9_]{1,50})', '', entity)\n",
        "  tokens = word_tokenize(text)\n",
        "  pos = pos_tag(tokens)\n",
        "  ner_tags = ne_chunk(pos, binary=False)\n",
        "  entity = \"\"\n",
        "  for tree in ner_tags.subtrees(filter=lambda t: t.label() == \"PERSON\"):\n",
        "    for leaf in tree.leaves():\n",
        "      array.append(leaf[0])\n",
        "    if len(array) == 2:\n",
        "      person = ' '.join(array)\n",
        "      people.append(person)\n",
        "    array = []\n",
        "  return people"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PyXBSaun52E"
      },
      "source": [
        "def populate_potential_people_nominees(filtered_tweets,award_keywords):\n",
        "  stretch = 3\n",
        "  potential_nominees = {}\n",
        "  prior_keywords = ['won','win','deserve','deserving','deserved','nomination','nominated','snubbed','better','is up for']\n",
        "  posterior_keywords = ['nominee','deserved award for','preferred','goes to','over','would have been','awarded to','should have','go to','should have been']\n",
        "  biside_keywords = ['nom','beat','rob','beats','winner','beating','loser','losers','wins over','stole','loses','lost']\n",
        "  negative_indicating_keywords = 'nominated|nominee|nomination|nominations|nom'\n",
        "  negative_keywords = 'should have|did not|should\\'ve|not|reject|didn\\'t'\n",
        "  for tweet in filtered_tweets:\n",
        "    text = tweet.lower()\n",
        "    check = 0\n",
        "    if re.search(negative_indicating_keywords,text) and re.search(negative_keywords,text):\n",
        "      continue\n",
        "    for keyword in prior_keywords:\n",
        "      if keyword in text:\n",
        "        check = 1\n",
        "        small_tweet = tweet[:re.search(keyword,text).start()]\n",
        "        tokens = small_tweet.split()\n",
        "        if len(tokens) == 0:\n",
        "          continue\n",
        "        elif len(tokens) <= stretch:\n",
        "          small_tweet = ' '.join(tokens)\n",
        "          #small_tweet = remove_stop_words(small_tweet)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "        else:\n",
        "          small_tweet = ' '.join(tokens[-stretch:])\n",
        "          #small_tweet = remove_stop_words(small_tweet)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "          small_tweet = ' '.join(tokens[0:-stretch])\n",
        "          #small_tweet = remove_stop_words(small_tweet)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 10)\n",
        "        #person_ents = return_persons_2_tokens(small_tweet)\n",
        "        #add_to_dictionary(potential_nominees,person_ents,weightage = 20)\n",
        "    for keyword in posterior_keywords:\n",
        "      if keyword in text:\n",
        "        check = 1\n",
        "        small_tweet = tweet[re.search(keyword,text).start():]\n",
        "        tokens = small_tweet.split()\n",
        "        if len(tokens) <= 1:\n",
        "          continue\n",
        "        tokens = tokens[1:]\n",
        "        if len(tokens) <= stretch:\n",
        "          small_tweet = ' '.join(tokens)\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "        else:\n",
        "          small_tweet = ' '.join(tokens[0:stretch])\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 20)\n",
        "          small_tweet = ' '.join(tokens[stretch:])\n",
        "          person_ents = return_persons_2_tokens(small_tweet,award_keywords)\n",
        "          add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 10)\n",
        "        #small_tweet = ' '.join(tokens)\n",
        "        #person_ents = return_persons_2_tokens(small_tweet)\n",
        "        #add_to_dictionary(potential_nominees,person_ents,weightage = 20)\n",
        "    for keyword in biside_keywords:\n",
        "      if keyword in text:\n",
        "        check = 1\n",
        "        small_tweet_left = tweet[:re.search(keyword,text).start()]\n",
        "        small_tweet_right = tweet[re.search(keyword,text).start():]\n",
        "        tokens_left = small_tweet_left.split()\n",
        "        tokens_right = small_tweet_right.split()\n",
        "        if len(tokens_left) > 0:\n",
        "          if len(tokens_left) <= stretch:\n",
        "            small_tweet_left = ' '.join(tokens_left)\n",
        "            person_ents_left = return_persons_2_tokens(small_tweet_left,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_left,award_keywords,weightage = 20)\n",
        "          else:\n",
        "            small_tweet_left = ' '.join(tokens_left[-stretch:])\n",
        "            person_ents_left = return_persons_2_tokens(small_tweet_left,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_left,award_keywords,weightage = 20)\n",
        "            small_tweet_left = ' '.join(tokens_left[0:-stretch])\n",
        "            person_ents_left = return_persons_2_tokens(small_tweet_left,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_left,award_keywords,weightage = 10)\n",
        "        if len(tokens_right) > 1:\n",
        "          tokens_right = tokens_right[1:]\n",
        "          if len(tokens_right) <= stretch:\n",
        "            small_tweet_right = ' '.join(tokens_right)\n",
        "            person_ents_right = return_persons_2_tokens(small_tweet_right,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_right,award_keywords,weightage = 20)\n",
        "          else:\n",
        "            small_tweet_right = ' '.join(tokens_right[0:stretch])\n",
        "            person_ents_right = return_persons_2_tokens(small_tweet_right,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_right,award_keywords,weightage = 20)\n",
        "            small_tweet_right = ' '.join(tokens_right[stretch:])\n",
        "            person_ents_right = return_persons_2_tokens(small_tweet_right,award_keywords)\n",
        "            add_to_dictionary(potential_nominees,person_ents_right,award_keywords,weightage = 10)\n",
        "        #person_ents_left = return_persons_2_tokens(small_tweet_left)\n",
        "        #person_ents_right = return_persons_2_tokens(small_tweet_right)\n",
        "        #add_to_dictionary(potential_nominees,person_ents_left,weightage = 20)\n",
        "        #add_to_dictionary(potential_nominees,person_ents_right,weightage = 20)\n",
        "    if check == 0:\n",
        "      person_ents = return_persons_2_tokens(tweet,award_keywords)\n",
        "      add_to_dictionary(potential_nominees,person_ents,award_keywords,weightage = 10)\n",
        "  return potential_nominees\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEvo2zxZTdDV",
        "outputId": "a9ef0f10-78c4-42f7-96bb-af4110a01183"
      },
      "source": [
        "array = [1,2,3,4,5,6,4,5,6]\n",
        "print(array[0:-3])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XD1WkDa5seS"
      },
      "source": [
        "def get_cosine(vec1, vec2):\n",
        "    # print vec1, vec2\n",
        "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
        "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
        "\n",
        "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
        "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
        "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
        "\n",
        "    if not denominator:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return float(numerator) / denominator\n",
        "\n",
        "def text_to_vector(text):\n",
        "    return Counter(WORD.findall(text))\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a = text_to_vector(a.strip().lower())\n",
        "    b = text_to_vector(b.strip().lower())\n",
        "\n",
        "    return get_cosine(a, b)\n",
        "\n",
        "##################testing function###############\n",
        "#print(cosine_similarity('steven ','steven speilberg'))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J13plzmG51rI"
      },
      "source": [
        "def char_similarity(a,b):\n",
        "  final_similarity = 0\n",
        "  a = a.lower()\n",
        "  b = b.lower()\n",
        "  a_tokens = a.split()\n",
        "  b_tokens = b.split()\n",
        "  for a_token in a_tokens:\n",
        "    for b_token in b_tokens:\n",
        "      similarity = 0\n",
        "      if len(a_token) > len(b_token):\n",
        "        bigger_token = a_token\n",
        "        smaller_token = b_token\n",
        "      else:\n",
        "        bigger_token = b_token\n",
        "        smaller_token = a_token\n",
        "      for i in range(len(smaller_token)):\n",
        "        if smaller_token[i] == bigger_token[i]:\n",
        "          similarity += 1\n",
        "      if final_similarity < similarity/len(smaller_token):\n",
        "        final_similarity = similarity/len(smaller_token)\n",
        "  return final_similarity\n",
        "\n",
        "##############testing function###################\n",
        "#print(char_similarity('ang lee','anger'))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpkaMqtC7-UU",
        "outputId": "56a7c553-c526-4c95-9bce-73e87928f8c0"
      },
      "source": [
        "def merge_potential_nominees(potential_nominees):\n",
        "  compressed_nominees = {}\n",
        "  potential_nominees = sorted(potential_nominees.items(), key = lambda k: -k[1])\n",
        "  potential_nominees = dict(potential_nominees)\n",
        "  for key1 in potential_nominees.keys():\n",
        "    if len(compressed_nominees) == 0:\n",
        "      compressed_nominees[key1] = potential_nominees[key1]\n",
        "    else:\n",
        "      for key2 in list(compressed_nominees.keys()):\n",
        "        #if cosine_similarity(key1,key2) >= 0.6:\n",
        "        if len(difflib.get_close_matches(key1,[key2],cutoff = 0.5))==1:\n",
        "          compressed_nominees[key2] += potential_nominees[key1]\n",
        "          break\n",
        "        else:\n",
        "          if key2 == list(compressed_nominees.keys())[-1]:\n",
        "            compressed_nominees[key1] = potential_nominees[key1]\n",
        "  return compressed_nominees\n",
        "\n",
        "##############testing function###################\n",
        "#tweet_data = open_jsonfile(data_path = 'sample_data/gg2013.json')\n",
        "#award_keywords = clean_award_name(\"best supporting actress in a motion picture\")\n",
        "#relevant_tweets = award_relevant_tweets(tweet_data, award_keywords)\n",
        "#potential_nominees = populate_potential_movie_nominees(relevant_tweets)\n",
        "#merged_nominees = merge_potential_nominees(potential_nominees)\n",
        "#for key in merged_nominees.keys():\n",
        "#  print(key,merged_nominees[key])\n",
        "print(difflib.get_close_matches('ang lee',['mind blo'],cutoff = 0.4))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mind blo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN-4Td4c6Rbq",
        "outputId": "deed370d-cfdf-476d-9f33-518c012f18ce"
      },
      "source": [
        "def check_on_imdb(merged_potential_nominees):\n",
        "  merged_potential_nominees = sorted(merged_potential_nominees.items(), key = lambda k: -k[1])\n",
        "  merged_potential_nominees = dict(merged_potential_nominees)\n",
        "  result_nominees = []\n",
        "  count = 0\n",
        "  for key in merged_potential_nominees.keys():\n",
        "    if len(key.split()) <= 1:\n",
        "      continue\n",
        "    persons_identified = ia.search_person(key)\n",
        "    if len(persons_identified) != 0:\n",
        "      #print(key,persons_identified[0])\n",
        "      if (cosine_similarity(key,persons_identified[0]['name'])+char_similarity(key,persons_identified[0]['name']))/2 >= 0.7:\n",
        "        if len(result_nominees) == 0:\n",
        "          result_nominees.append(persons_identified[0]['name'])\n",
        "          count += 1\n",
        "        elif persons_identified[0]['name'] not in result_nominees:\n",
        "          result_nominees.append(persons_identified[0]['name'])\n",
        "          count += 1\n",
        "      if count == 5 :\n",
        "        break\n",
        "  return result_nominees\n",
        "################testing function####################\n",
        "#result_nominees = check_on_imdb(merged_nominees)\n",
        "print(ia.search_person('tommy lee')[0]['name'])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tommy Lee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGbRrKHs_rk7"
      },
      "source": [
        "tweet_data = open_jsonfile()\n",
        "def find_nominees(award_name,tweet_data):\n",
        "  #clean the award name and take it as list of tokens\n",
        "  award_keywords = clean_award_name(award_name)\n",
        "  #find all tweets relevant to this award name\n",
        "  filtered_tweets = award_relevant_tweets(tweet_data,award_keywords)\n",
        "  #if award_name == 'best performance by an actor in a television series - comedy or musical':\n",
        "  #  for tweet in filtered_tweets:\n",
        "  #    print(tweet)\n",
        "  #print(filtered_tweets)\n",
        "  #find potential nominees from relevant tweets\n",
        "  potential_nominees = populate_potential_people_nominees(filtered_tweets,award_keywords)\n",
        "  #print(potential_nominees)\n",
        "  #print(potential_nominees)\n",
        "  #merge potential nominees if there are various version of same nominees\n",
        "  merged_potential_nominees = merge_potential_nominees(potential_nominees)\n",
        "  print(merged_potential_nominees)\n",
        "  #print(merged_potential_nominees)\n",
        "  #query imdb for best five results\n",
        "  results = check_on_imdb(merged_potential_nominees)\n",
        "  #return top five results\n",
        "  return results\n",
        "#winners = ['Ben Affleck','Lena Dunham']\n"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4_51CdGAkF9",
        "outputId": "5ca4db8e-2f01-4d72-9edc-7ecebf67667a"
      },
      "source": [
        "find_nominees('best performance by an actor in a television series - comedy or musical',tweet_data)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'don cheadle': 290, 'jim parsons': 10}\n",
            "{'don cheadle': 290, 'jim parsons': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdC5t7Q08c0h",
        "outputId": "60934723-a7e8-4963-f9f9-d4ab351b05d9"
      },
      "source": [
        "for award_name in PEOPLE_AWARDS:\n",
        "  print('---------------------------------')\n",
        "  print(award_name)\n",
        "  print(find_nominees(award_name,tweet_data))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "best director - motion picture\n",
            "{'ben affleck': 3000, 'oscar snub': 110, 'ang lee': 30, 'jared leto': 20, 'quentin tarantino': 30, 'halle berry': 20, 'steven spielberg': 20, 'mind blo': 20, 'watch ben': 30, 'jennifer garner': 20, 'argo takes': 30, 'speilberg lincoln': 20, 'ben critics': 10, 'joe wright': 10, 'jodie foster': 10, 'matt damon': 10, 'django argo': 20, 'jon hamm': 10}\n",
            "['Ben Affleck', 'Oscar Snel', 'Ang Lee', 'Quentin Tarantino', 'Jared Leto']\n",
            "---------------------------------\n",
            "best performance by an actress in a television series - comedy or musical\n",
            "{'lena dunham': 240, 'jennifer lawrence': 20}\n",
            "['Lena Dunham', 'Jennifer Lawrence']\n",
            "---------------------------------\n",
            "best performance by an actor in a supporting role in a motion picture\n",
            "{'christoph waltz': 1740, 'django unchained': 110, 'tommy lee': 40, 'alan arkin': 20, 'lee jones': 20, 'leonardo dicaprio': 30, 'garrett hedlund': 20, 'daniel lewis': 10, 'mimin movie': 10, 'les miserable': 10, 'george w': 10}\n",
            "['Christoph Waltz', 'Tommy Lee', 'Leonardo DiCaprio', 'Alan Arkin', 'Lee Jones']\n",
            "---------------------------------\n",
            "best performance by an actress in a supporting role in a series, mini-series or motion picture made for television\n",
            "{'maggie smith': 50}\n",
            "['Maggie Smith']\n",
            "---------------------------------\n",
            "best performance by an actress in a motion picture - comedy or musical\n",
            "{'jennifer lawrence': 940, 'hathaway waltz': 100, 'les misérables': 30, 'naomi watts': 10, 'linings playbook': 10, 'leana dunham': 20}\n",
            "['Jennifer Lawrence', 'Les Misérables', 'Lena Dunham', 'Naomi Watts', 'Silver Linings Playbook']\n",
            "---------------------------------\n",
            "best performance by an actress in a television series - drama\n",
            "{'claire danes': 380, 'lea michele': 20, 'maggie smith': 10, 'damien lewis': 10, 'jessica chastain': 10}\n",
            "['Claire Danes', 'Lea Michele', 'Maggie Smith', 'Damien Lewis', 'Jessica Chastain']\n",
            "---------------------------------\n",
            "best performance by an actress in a motion picture - drama\n",
            "{'jessica chastain': 1870, 'jennifer lawrence': 40, 'naomi watts': 30, 'maggie smith': 20, 'michelle dockery': 30, 'anne hathaway': 20, 'clare danes': 60, 'les mis': 10}\n",
            "['Jessica Chastain', 'Claire Danes', 'Jennifer Lawrence', 'Naomi Watts', 'Michelle Dockery']\n",
            "---------------------------------\n",
            "best performance by an actor in a motion picture - comedy or musical\n",
            "{'hugh jackman': 890, 'les miserables': 130, 'louis louie': 10, 'jack black': 10}\n",
            "['Hugh Jackman', 'Les Miserables', 'Louis Lombardi', 'Jack Black']\n",
            "---------------------------------\n",
            "best performance by an actor in a supporting role in a series, mini-series or motion picture made for television\n",
            "{'ed harris': 40, 'maggie smith': 10}\n",
            "['Ed Harris', 'Maggie Smith']\n",
            "---------------------------------\n",
            "best performance by an actress in a supporting role in a motion picture\n",
            "{'anne hathaway': 1880, 'maggie smith': 170, 'les miserables': 190, 'jennifer lawrence': 50, 'sally field': 30, 'congratz anne': 30, 'nicole kidman': 10, 'yesss anne': 10}\n",
            "['Anne Hathaway', 'Les Miserables', 'Maggie Smith', 'Jennifer Lawrence', 'Sally Field']\n",
            "---------------------------------\n",
            "best performance by an actor in a mini-series or motion picture made for television\n",
            "{'kevin costner': 150, 'ed harris': 50, 'maggie smith': 10}\n",
            "['Kevin Costner', 'Ed Harris', 'Maggie Smith']\n",
            "---------------------------------\n",
            "best performance by an actress in a mini-series or motion picture made for television\n",
            "{'julianne moore': 160, 'maggie smith': 50, 'nicole kidman': 20}\n",
            "['Julianne Moore', 'Maggie Smith', 'Nicole Kidman']\n",
            "---------------------------------\n",
            "best performance by an actor in a motion picture - drama\n",
            "{'daniel lewis': 500, 'christoph waltz': 100, 'leo dicaprio': 20, 'lewis lincoln': 20, 'okay jokes': 10, 'tony kushner': 10, 'hugh jackman': 10}\n",
            "['Daniel Lewis', 'Christoph Waltz', 'Leonardo DiCaprio', 'Lincoln Lewis', 'Tony Kushner']\n",
            "---------------------------------\n",
            "best performance by an actor in a television series - drama\n",
            "{'damian lewis': 370, 'bill clinton': 20, 'serie dramatica': 10, 'connie britton': 10, 'lewinsky scandal': 10}\n",
            "['Damian Lewis', 'Bill Clinton', 'Connie Britton']\n",
            "---------------------------------\n",
            "best performance by an actor in a television series - comedy or musical\n",
            "{'don cheadle': 290, 'jim parsons': 10}\n",
            "['Don Cheadle', 'Jim Parsons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wADXUckFD9oI",
        "outputId": "052a8342-f378-42fd-ba48-313c2d0f86c6"
      },
      "source": [
        "tweet_data = open_jsonfile(data_path = 'sample_data/gg2013.json')\n",
        "#print(tweet_data[0])\n",
        "for data in tweet_data:\n",
        "  if 'rt @' in data['text'].lower():\n",
        "    continue\n",
        "  if 'christoph waltz' in data['text'].lower() and re.search('best',data['text'].lower())and re.search('actor',data['text'].lower()) and re.search('drama',data['text'].lower()) :\n",
        "    print (data['text'])\n",
        "    print()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Supporting Actor - Drama: Christoph Waltz - \"Django Unchained\" #GoldenGlobes\n",
            "\n",
            "cc @MindOfR . Again!“@eonline: Best Supporting Actor in a Drama: Christoph Waltz for Django Unchained! #GoldenGlobes http://t.co/rpl7AIty”\n",
            "\n",
            "Best Supporting Actor in a Drama: Christoph Waltz for Django Unchained! #GoldenGlobes http://t.co/pvovV3dY\n",
            "\n",
            "“@eonline: Best Supporting Actor in a Drama: Christoph Waltz for Django Unchained! #GoldenGlobes” TOTALLY deserved!\n",
            "\n",
            "Best Supporting Actor in a Drama: Christoph Waltz (Django Unchained) #GoldenGlobes\n",
            "\n",
            "He was awesome. @eonline Best Supporting Actor in a Drama: Christoph Waltz for Django Unchained! #GoldenGlobes http://t.co/xXUUMcqB\n",
            "\n",
            "Yei. \"@eonline: Best Supporting Actor in a Drama: Christoph Waltz for Django Unchained! #GoldenGlobes http://t.co/wSX4AapU\"\n",
            "\n"
          ]
        }
      ]
    }
  ]
}