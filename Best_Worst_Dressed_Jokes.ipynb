{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best Worst Dressed Jokes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN8ZJU5RDIJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a58aef5-318f-4a65-a8b5-84c44e091cae"
      },
      "source": [
        "import json\n",
        "import spacy\n",
        "import re\n",
        "import difflib as dl\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "file_path = '/content/drive/MyDrive/NLP/gg2013.json'\n",
        "\n",
        "#source1=https://catriscode.com/2021/03/02/extracting-or-removing-mentions-and-hashtags-in-tweets-using-python/\n",
        "#source2== https://stackoverflow.com/questions/38365389/compare-similarity-between-names/38365913"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSNrtUekDMwp"
      },
      "source": [
        "f = open(file_path)\n",
        "data = json.load(f)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "tweet_texts = []\n",
        "\n",
        "for tweet in data:\n",
        "  cleaned_tweet = re.sub('#([a-zA-Z0-9_]{1,50})', '', tweet['text'])\n",
        "  cleaned_tweet = re.sub('@([a-zA-Z0-9_]{1,50})', '', cleaned_tweet)\n",
        "  #cleaned_tweet = cleaned_tweet.lower()\n",
        "  if 'rt @' not in cleaned_tweet:\n",
        "    tweet_texts.append(cleaned_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ0nMdf4_EJe",
        "outputId": "65c2dbe0-165a-4949-b0fe-2fc82b5c4e25"
      },
      "source": [
        "def check_keyword(tweet_text,keywords):\n",
        "  \n",
        "  for keyword in keywords.split():\n",
        "    if keyword not in tweet_text and keyword != '-':\n",
        "      return False\n",
        "  return True\n",
        "\n",
        "print(check_keyword('nihaal subhash narayanan','nihaal narayanan'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdxCIdnpsNsu",
        "outputId": "74080755-b42e-463c-88fe-536c6fdc0f7e"
      },
      "source": [
        "dressed_keywords = ['best dressed|amazing dress|wow that dress|beautiful dress|best dressed|best dress','worst dressed|ugly dress|bad dress','funny|hilarous|haha']\n",
        "\n",
        "for dressed_keyword in dressed_keywords[:]:\n",
        "  answer = {}\n",
        "  for tweet_text in tweet_texts[:]:\n",
        "    dressed_keyword_index = re.search(dressed_keyword,tweet_text.lower())\n",
        "    if dressed_keyword_index:\n",
        "      doc = nlp(tweet_text)\n",
        "      for entity in doc.ents:\n",
        "        if entity.label_ == 'PERSON':\n",
        "          if entity.text in answer.keys():\n",
        "            answer[entity.text] = answer[entity.text] + 1\n",
        "          else:\n",
        "            answer[entity.text] = 1\n",
        "  answer = dict(sorted(answer.items(),key = lambda answer:answer[1],reverse=True))\n",
        "  if (len(answer.keys())!=0):\n",
        "    print(dressed_keyword,end= ' : ')\n",
        "    print(list(answer.keys())[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best dressed|amazing dress|wow that dress|beautiful dress|best dressed|best dress : ['Kate Hudson']\n",
            "worst dressed|ugly dress|bad dress : ['Halle Berry']\n",
            "funny|hilarous|haha : ['Amy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkQW7nBCWWCC"
      },
      "source": [
        "import csv\n",
        "tsv_file = open(\"/content/drive/MyDrive/NLP/data.tsv\")\n",
        "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
        "read_tsv = list(read_tsv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prv5GGxuh-gh"
      },
      "source": [
        "for year in range(2006,2022):\n",
        "  extfile = open('/content/drive/MyDrive/NLP/tvseries/'+str(year)+\".txt\", \"w\")\n",
        "  for row in read_tsv:\n",
        "    if row[1]=='tvSeries':\n",
        "      if (row[5].isnumeric() and row[6].isnumeric()):\n",
        "        if int(row[5])<=year and int(row[6])>=year:\n",
        "          extfile.write(row[2]+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNfAYQ9ZiVKZ"
      },
      "source": [
        "import csv\n",
        "csv_file = open(\"/content/drive/MyDrive/NLP/IMDb movies.csv\")\n",
        "read_csv = csv.reader(csv_file, delimiter=\",\")\n",
        "read_csv = list(read_csv)\n",
        "\n",
        "\n",
        "for year in range(2006,2022):\n",
        "  movies = {}\n",
        "  for row in read_csv[1:]:\n",
        "    if (row[3].isdigit()):\n",
        "      if int(row[3])==year:\n",
        "        movies[row[2]] = int(row[15])\n",
        "  movies = dict(sorted(movies.items(), key=lambda item: item[1],reverse=True)) \n",
        "  movies = list(movies.keys())[:1500]\n",
        "  extfile = open('/content/drive/MyDrive/NLP/movies/movies'+str(year)+\".txt\", \"w\")\n",
        "  for movie in movies:\n",
        "    extfile.write(movie+'\\n')\n",
        "           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DLZ55RcTwNL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDql6oP5jjGR"
      },
      "source": [
        "\n",
        "\n",
        "for year in range(2006,2022):\n",
        "  extfile = open('/content/drive/MyDrive/NLP/movies/movies'+str(year)+\".txt\", \"w\")\n",
        "  movie_list = []\n",
        "  for row in read_tsv:\n",
        "    if row[1]=='tvSeries':\n",
        "      if (row[5].isnumeric()):\n",
        "        if int(row[5])==year:\n",
        "          movie_list.append(row[2])\n",
        "          extfile.write(row[2]+'\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}